{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c0f56a",
   "metadata": {},
   "source": [
    "# Fulmine LABS mini-PACs\n",
    "\n",
    "## Overview\n",
    "\n",
    "Fulmine Labs will use medical images for various quality/testing related, machine learning (ML) initiatives. \n",
    "The best practice for managing this data is to use Digital Imaging and Communications in Medicine (DICOM) standard compliant images with a PACS-like system.\n",
    "\n",
    "The code in this project implements and tests a basic PACS with the following architecture:\n",
    "\n",
    "```\n",
    "[ Orthanc Repository (Open Source component) ]\n",
    "       |\n",
    "       | (DICOM Images) <----------------------------------------->  [ OHIF Viewer (Open Source component) ]\n",
    "       v\n",
    "[ Fulmine-Labs-Mini-PACS - Data Setup Script ]      \n",
    "       |\t\t\t\t\t\t\t\t\n",
    "       | (Metadata and generated images)   \n",
    "       |                                          \n",
    "[ SQLite Database ]\t\t\t\t\t\t\t\n",
    "       |\t\t\t\t\t\t\t\t\n",
    "       | (API Requests)\t\t\t\t\t\t \n",
    "       v\n",
    "[ Flask Application ]\n",
    "       |\n",
    "       | (HTTP Requests for Data)\n",
    "       v\n",
    "[ Client (Pytest, Browser) ]\n",
    "       |\n",
    "       | (Model Training Data)\n",
    "       v\n",
    "[ Anomaly Detection Model Training Script (separate repository) ]\n",
    "\n",
    "```\n",
    "\n",
    "The data setup script will traverse all folders in a specified location, identify DICOM images and if they have appropriate Window Center and Width DICOM header information, will convert them to PNG files at another specified location and add the related metadata to an SQLite database. \n",
    "\n",
    "The database maintains the Patient -> Study -> Series -> Image relationship, as well as tracking the output image file names and parameters used in their creation, allowing PACS-like SQL queries to be constructed. \n",
    "\n",
    "\n",
    "## Author\n",
    "Duncan Henderson\n",
    "Fulmine Labs LLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1476f8f-4aec-4256-ac40-f7ef97a92337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pydicom\n",
    "import sqlite3\n",
    "import shutil \n",
    "import logging\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27aa2457-15bd-4d94-96ae-2ab7e7496079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run variables\n",
    "\n",
    "# Define a verbose flag (set it to True for verbose output)\n",
    "#verbose = True\n",
    "verbose = False\n",
    "\n",
    "source_dir = r'D:\\\\Orthanc'\n",
    "target_dir = r'D:\\\\training' # The output PNG files will be written to the same folder name with _png appended\n",
    "training_ratio, validation_ratio = 0.7, 0.15\n",
    "\n",
    "# Variable to control database deletion\n",
    "delete_db = True\n",
    "db_path = 'medical_imaging.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95a0008-2899-41ad-a9a3-9499e811cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to a log file that is specific for the test run and also to the screen if verbose is set\n",
    "\n",
    "class CustomLogger:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Configure logging\n",
    "        logging.basicConfig(filename=f'log_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log', level=logging.INFO)\n",
    "\n",
    "    def iprint(self, message):\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "        logging.info(message)\n",
    "        \n",
    "    def eprint(self, message):\n",
    "        if self.verbose:\n",
    "            print(message)\n",
    "        logging.error(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0cb8d8-f886-4d4f-bd1b-29329dc3f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_database(db_path):\n",
    "    \n",
    "    # Connect to SQLite database (this will create the database if it doesn't exist)\n",
    "    \n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create tables\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS Patients (\n",
    "                            PatientID TEXT PRIMARY KEY,\n",
    "                            PatientInfo TEXT)''')\n",
    "\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS Studies (\n",
    "                            StudyID TEXT PRIMARY KEY,\n",
    "                            PatientID TEXT,\n",
    "                            StudyDate TEXT,\n",
    "                            StudyDescription TEXT,\n",
    "                            BodyPartExamined TEXT,\n",
    "                            FOREIGN KEY (PatientID) REFERENCES Patients (PatientID))''')\n",
    "\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS Series (\n",
    "                            SeriesID TEXT PRIMARY KEY,\n",
    "                            StudyID TEXT,\n",
    "                            SeriesDate TEXT,\n",
    "                            SeriesDescription TEXT,\n",
    "                            Modality TEXT,\n",
    "                            FOREIGN KEY (StudyID) REFERENCES Studies (StudyID))''')\n",
    "\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS Images (\n",
    "                            ImageID TEXT PRIMARY KEY,\n",
    "                            SeriesID TEXT,\n",
    "                            FilePath TEXT,\n",
    "                            State TEXT,\n",
    "                            PngFilePath TEXT,\n",
    "                            WindowCenter TEXT,\n",
    "                            WindowWidth TEXT,\n",
    "                            RescaleIntercept TEXT,\n",
    "                            RescaleSlope TEXT,\n",
    "                            InstanceNumber TEXT,\n",
    "                            FOREIGN KEY (SeriesID) REFERENCES Series (SeriesID))''')\n",
    "\n",
    "    except sqlite3.DatabaseError as e:\n",
    "        logger.eprint(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19776f13-ce4a-4ea0-bfd5-d77c57128b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(query, args=()):\n",
    "    with sqlite3.connect(\"medical_imaging.db\") as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query, args)\n",
    "        data = cursor.fetchall()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0cc0e11-ec45-49e5-862f-9b9c7c937265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dicom_file(file_path):\n",
    "    try:\n",
    "        pydicom.dcmread(file_path, stop_before_pixels=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.eprint(f\"Error reading DICOM file {file_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4edcccb3-3134-498b-84db-df8545c3690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(file_list, destination):\n",
    "    try:\n",
    "        os.makedirs(destination, exist_ok=True)\n",
    "        for file_path in file_list:\n",
    "            shutil.copy(file_path, os.path.join(destination, os.path.basename(file_path)))\n",
    "    except (FileNotFoundError, PermissionError) as e:\n",
    "        logger.eprint(f\"File I/O error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ef79f8e-be98-4509-96b3-38e6180117ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(dicom_file_path):\n",
    "    # Extract metadata like PatientID, StudyID, SeriesID, ImageID, Modality, and BodyPart\n",
    "    ds = pydicom.dcmread(dicom_file_path, stop_before_pixels=True)\n",
    "    patient_id = ds.PatientID\n",
    "    study_id = ds.StudyInstanceUID\n",
    "    series_id = ds.SeriesInstanceUID\n",
    "    image_id = ds.SOPInstanceUID\n",
    "    study_description = ds.StudyDescription if 'StudyDescription' in ds else 'N/A'\n",
    "    series_description = ds.SeriesDescription if 'SeriesDescription' in ds else 'N/A'\n",
    "    instance_number = ds.InstanceNumber if 'InstanceNumber' in ds else 'N/A'\n",
    "    modality = ds.Modality if 'Modality' in ds else 'N/A'\n",
    "    body_part_examined = ds.BodyPartExamined if 'BodyPartExamined' in ds else 'N/A'\n",
    "    study_date = ds.StudyDate if 'StudyDate' in ds else 'N/A'\n",
    "    series_date = ds.SeriesDate if 'SeriesDate' in ds else 'N/A'\n",
    " \n",
    "    return patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1d1262-c3d7-4a69-b134-aa736c9f2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_metadata_into_db(cursor, patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date, file_path, state):\n",
    "    \n",
    "    # Insert data into the Patients table\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO Patients (PatientID) VALUES (?)\", (patient_id,))\n",
    "\n",
    "    # Insert data into the Studies table\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO Studies (StudyID, PatientID, StudyDate, StudyDescription, BodyPartExamined) VALUES (?, ?, ?, ?, ?)\",\n",
    "                   (study_id, patient_id, study_date, study_description, body_part_examined))  # Replace \"StudyDate\" with actual values if needed\n",
    "\n",
    "    # Insert data into the Series table\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO Series (SeriesID, StudyID, SeriesDate, SeriesDescription, Modality) VALUES (?, ?, ?, ?, ?)\",\n",
    "                   (series_id, study_id, series_date, series_description, modality))  # Replace \"SeriesDate\" with actual values if needed\n",
    "\n",
    "    # Insert data into the Images table\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO Images (ImageID, SeriesID, FilePath, State, InstanceNumber) VALUES (?, ?, ?, ?, ?)\", \n",
    "                   (image_id, series_id, file_path, state, instance_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1ee840-7d8c-48f2-a5d5-4214c3059a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rescale(dcm):\n",
    "    \"\"\"Apply the rescale slope and intercept to the DICOM image data.\"\"\"\n",
    "    rescaled_image = dcm.pixel_array.astype(np.float64) * dcm.RescaleSlope + dcm.RescaleIntercept\n",
    "    return rescaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea251964-7122-45ff-9dcb-6af64824a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_image(image, window_center, window_width):\n",
    "    \"\"\"Apply the windowing (level and width) to the image data.\"\"\"\n",
    "    img_min = window_center - window_width / 2\n",
    "    img_max = window_center + window_width / 2\n",
    "    windowed_img = np.clip(image, img_min, img_max)\n",
    "    return windowed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ddfef1e-93e7-40c6-a24f-7abb6ddca8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"Normalize the image data to 0-255 and convert to uint8.\"\"\"\n",
    "    image = image - np.min(image)\n",
    "    image = image / np.max(image)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e49e23cf-a797-4df0-a56f-92c98c3e0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_value(dicom_value):\n",
    "    \"\"\"Retrieve the first value from DICOM elements that could be multi-valued and convert to float.\"\"\"\n",
    "    if isinstance(dicom_value, pydicom.multival.MultiValue):\n",
    "        return float(dicom_value[0])\n",
    "    else:\n",
    "        return float(dicom_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfaf6adf-9301-49eb-bf49-b3df5e19f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dicom_to_png(dicom_dir, output_dir, state, cursor):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for entry in os.listdir(dicom_dir):\n",
    "            logger.iprint (\"Processing DICOM file: \" + entry)\n",
    "            dicom_path = os.path.join(dicom_dir, entry)\n",
    "            if os.path.isfile(dicom_path):  # Check if it's a file\n",
    "                try:\n",
    "                    dcm = pydicom.dcmread(dicom_path)\n",
    "\n",
    "                    # Apply Rescale Slope and Intercept\n",
    "                    rescaled_image = apply_rescale(dcm)\n",
    "\n",
    "                    # Initialize normalized_image\n",
    "                    normalized_image = None\n",
    "\n",
    "                    # Check for window center and width\n",
    "                    if hasattr(dcm, 'WindowCenter') and hasattr(dcm, 'WindowWidth'):\n",
    "                        window_center = get_first_value(dcm.WindowCenter)\n",
    "                        window_width = get_first_value(dcm.WindowWidth)\n",
    "                        windowed_image = window_image(rescaled_image, window_center, window_width)\n",
    "                        normalized_image = normalize_image(windowed_image)\n",
    "\n",
    "                    # If no windowing is possible, handle the scenario\n",
    "                    if normalized_image is None:\n",
    "                        logger.iprint(f\"No window center/width or unable to process windowing for file \" + entry + \", skipping.\")\n",
    "                        continue  # Skip this file\n",
    "\n",
    "                    # Generate PNG filename and save the PNG image\n",
    "                    png_filename = entry + '.png'\n",
    "                    png_path = os.path.join(output_dir, png_filename)\n",
    "                    png_image = Image.fromarray(normalized_image)\n",
    "                    png_image.save(png_path)\n",
    "\n",
    "                    # Extract image ID and metadata\n",
    "                    image_id = dcm.SOPInstanceUID\n",
    "                    rescale_intercept = str(dcm.RescaleIntercept if \"RescaleIntercept\" in dcm else \"N/A\")\n",
    "                    rescale_slope = str(dcm.RescaleSlope if \"RescaleSlope\" in dcm else \"N/A\")\n",
    "\n",
    "                    # Update the database\n",
    "                    cursor.execute(\"UPDATE Images SET PngFilePath = ?, WindowCenter = ?, WindowWidth = ?, RescaleIntercept = ?, RescaleSlope = ? WHERE ImageID = ?\", \n",
    "                                   (png_path, window_center, window_width, rescale_intercept, rescale_slope, image_id))\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.eprint(f\"Failed to convert: \" + dicom_path + \", Error: {e}\")\n",
    "\n",
    "    except pydicom.errors.InvalidDicomError as e:\n",
    "            logger.eprint(f\"Invalid DICOM file {dicom_path}: {e}\")    \n",
    "    except IOError as e:\n",
    "            logger.eprint(f\"I/O error with file {dicom_path}: {e}\")\n",
    "    except Exception as e:\n",
    "            logger.eprint(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb0c62a2-3362-4772-816b-2dbde893ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code execution\n",
    "logger = CustomLogger(verbose)\n",
    "\n",
    "# Check if the database exists and delete it if delete_db is True\n",
    "if delete_db and os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "    logger.iprint(\"Existing database removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e89a1ace-23f8-44ff-83e2-f048d1b57586",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_database(db_path)\n",
    "# In your main function or processing script\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e28f8e68-85a0-475d-be97-bcf375d3cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the DIDOM files from the image archive and add them to the database\n",
    "dicom_files = []\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if is_dicom_file(file_path):\n",
    "            dicom_files.append(file_path)\n",
    "\n",
    "random.shuffle(dicom_files)\n",
    "total_files = len(dicom_files)\n",
    "training_count = int(total_files * training_ratio)\n",
    "validation_count = int(total_files * validation_ratio)\n",
    "\n",
    "training_files = dicom_files[:training_count]\n",
    "validation_files = dicom_files[training_count:training_count + validation_count]\n",
    "test_files = dicom_files[training_count + validation_count:]\n",
    "\n",
    "for file_path in training_files:\n",
    "    patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date = extract_metadata(file_path)\n",
    "    insert_metadata_into_db(cursor, patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date, file_path, 'train')\n",
    "\n",
    "for file_path in validation_files:\n",
    "    patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date = extract_metadata(file_path)\n",
    "    insert_metadata_into_db(cursor, patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date, file_path, 'validate')\n",
    "\n",
    "for file_path in test_files:\n",
    "    patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date = extract_metadata(file_path)\n",
    "    insert_metadata_into_db(cursor, patient_id, study_id, series_id, image_id, modality, body_part_examined, instance_number, study_description, series_description, study_date, series_date, file_path, 'test')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "copy_files(training_files, os.path.join(target_dir, 'train\\\\valid'))\n",
    "copy_files(validation_files, os.path.join(target_dir, 'validate\\\\valid'))\n",
    "copy_files(test_files, os.path.join(target_dir, 'test\\\\valid'))\n",
    "\n",
    "logger.iprint(f\"Total DICOM files: \" + str(total_files))\n",
    "logger.iprint(f\"Training files: \" + str(len(training_files)))\n",
    "logger.iprint(f\"Validation files: \" + str(len(validation_files)))\n",
    "logger.iprint(f\"Test files: \" + str(len(test_files)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f824ef3-b7e4-4fbd-86fc-236ac1393205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After inserting DICOM metadata...\n",
    "# Create the PNG files for training\n",
    "convert_dicom_to_png(os.path.join(target_dir, 'train\\\\valid'), os.path.join(target_dir, '..', 'training_png', 'train', 'valid'), 'train', cursor)\n",
    "convert_dicom_to_png(os.path.join(target_dir, 'validate\\\\valid'), os.path.join(target_dir, '..', 'training_png', 'validate', 'valid'), 'validate', cursor)\n",
    "convert_dicom_to_png(os.path.join(target_dir, 'test\\\\valid'),os.path.join(target_dir, '..', 'training_png', 'test', 'valid'), 'test', cursor)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67a31611-1d70-4c43-8ac3-9ff65350528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00aa8279-deeb-45d7-84e1-f7680656e6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.iprint (\"Start DB API with python flask_API.py\")\n",
    "logger.iprint (\"Run tests with pytest -v test_API.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
